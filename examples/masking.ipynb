{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbasecondab23bab91986d4c1c9f041b64fa30f1ad",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nested tensor masking\n",
    "\n",
    "'''\n",
    "NestedTensor comes with two APIs that allow representing a NestedTensor as a pair of a data tensor with a mask tensor and another way around. \n",
    "Essentially, data tensor stores all the values, nesting, dimensionality, and metadata(dtype, layout, etc.) of the original NestedTensor. As NestedTensor allows tensors of different sizes, result data tensor will be padded. Therefore a mask is required to tell us which values are real and which ones are padding. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to_tensor_mask\n",
    "# data_tensor, mask = nt.to_tensor_mask(mask_dim=None)\n",
    "# data_tensor - result data tensor.\n",
    "# mask - result mask.\n",
    "# nt - original nested tensor.\n",
    "# mask_dim - desired dimensionality of the resulting mask.\n",
    "\n",
    "'''\n",
    "This method returns a data tensor with a mask that represents nested tensor. Result data tensor is always the same for a given nested tensor no matter what mask_dim is passed. This tensor represents all the values, dimensionality, and nesting of the original nested tensor.\n",
    "The resulting mask depends on mask_dim value. It's important to understand the relationship between data tensor and a mask. The same nested tensor can be represented with a few combinations of the same data tensor and masks of different dimensionality. If no value for mask_dim was passed, the mask with the lowest possible dimensionality would be returned. It's easier to understand by looking at the examples.\n",
    "'''\n",
    "import torch\n",
    "import nestedtensor as nt\n",
    "\n",
    "a = nt.nested_tensor([\n",
    "                nt.nested_tensor([\n",
    "                    torch.tensor([1])\n",
    "                ]),\n",
    "                nt.nested_tensor([\n",
    "                    torch.tensor([2])\n",
    "                ]),\n",
    "                nt.nested_tensor([\n",
    "                    torch.tensor([3])\n",
    "                ])\n",
    "            ])\n",
    "tensor, mask = a.to_tensor_mask()\n",
    "print(\"\\n\\nmask_dim = None\")\n",
    "print(\"Data tensor: \", tensor)\n",
    "print(\"Mask: \", mask)\n",
    "\n",
    "# As you can see, we have only a boolean scalar which tells us that no elements from data tensor should be ignored. This is possible only in cases when we have nested tensor where all the leaf nodes have the same size.\n",
    "\n",
    "tensor, mask = a.to_tensor_mask(mask_dim=3)\n",
    "# Data tensor will always be the same\n",
    "print(\"\\n\\nmask_dim = 3\")\n",
    "print(\"Data tensor: \", tensor)\n",
    "\n",
    "# This is the highest dimensionality of the mask that we can get for a given nested tensor. We can see mask value per each tensor element.\n",
    "print(\"Mask: \", mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Mask dimension is too small to represent data tensor.\nMask dimension is bigger than nested dimension of a nested tensor.\n"
    }
   ],
   "source": [
    "# If the desired mask dimension is too small or too big to represent the nested tensor, an error will be thrown.\n",
    "a = nt.nested_tensor([\n",
    "            torch.tensor([1, 2,]),\n",
    "            torch.tensor([3, 4, 5, 6]),\n",
    "        ])\n",
    "\n",
    "try:\n",
    "    a.to_tensor_mask(mask_dim=1)\n",
    "except RuntimeError as error:\n",
    "    print(error)\n",
    "\n",
    "try:\n",
    "    a.to_tensor_mask(mask_dim=10)\n",
    "except RuntimeError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "nested_dim = 1\nnested_tensor([\n\ttensor([1, 2, 3]),\n\ttensor([4])\n])\n\nnested_dim = 2\nnested_tensor([\n\tnested_tensor([\n\t\ttensor(1),\n\t\ttensor(2),\n\t\ttensor(3)\n\t]),\n\tnested_tensor([\n\t\ttensor(4)\n\t])\n])\n"
    }
   ],
   "source": [
    "## nested_tensor_from_tensor_mask\n",
    "# result_nt = nested_tensor.nested_tensor_from_tensor_mask(tensor, mask, nested_dim=1)\n",
    "# result_nt - result nested tensor\n",
    "# tensor - input data tensor\n",
    "# mask - input mask\n",
    "# nested_dim - desired nested dimensionality of the result nested tensor\n",
    "\n",
    "'''\n",
    "This method returns a nested tensor which was constructed from passed tensor, mask, and optional dimensionality value. \n",
    "Resulting nested tensor dimensionality depends on nested_dim value. nested_dim has a default value of 1 and has to be between 1 and data tensor dimensionality.\n",
    "'''\n",
    "\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 0, 0]])\n",
    "        \n",
    "mask = torch.tensor([[ True,  True,  True],\n",
    "                     [ True, False, False]])\n",
    "\n",
    "# nested_dim has a default value of 1\n",
    "print(\"nested_dim = 1\")\n",
    "print(nt.nested_tensor_from_tensor_mask(tensor, mask))\n",
    "\n",
    "print(\"\\nnested_dim = 2\")\n",
    "print(nt.nested_tensor_from_tensor_mask(tensor, mask, nested_dim = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}